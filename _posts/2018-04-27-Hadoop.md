---
layout: post
title: Hadoop入门
categories: 
    - 大数据
    - hadoop
description: 大数据
keywords: 大数据
comments: true
---

摘要：hadoop入门学习，原理介绍，重点记录在安装hadoop的过程，本文只记录正确的安装方式，没有记录在安装过程中的坑

### hadoop主要分为连个层次
    hadoop是一个框架，java编写
    
    －　加工和计算层
    －　存储层，hadoop分布式文件系统　　
    hadoop两个核心组件　　
        －　MapReduce
        －　HDFS
    hadoop框架两个模块：
        －　hadoop通用：这是Java库和其他Hadoop组件所需的实用工具
        －　hadoop　YARN：这是作业调度和集群资源管理的框架
    
#### MapReduce　　
    - 是一种编程模型，可在hadoop框架上运行,分布式计算
    
#### HDFS
    - 在普通硬件上运行分布式文件系统，提高吞吐量的应用数据访问
#### 基础核心：提供基础的通用的功能
#### YARN：资源分配（多个任务是排队执行还是同时执行）
    
    
### HDFS构成
    
    1) NameNode  用来存储数据的存放位置等元数据（不存放数据）

    2) DataNode 只用来存储数据

    3) SecondaryNameNode  辅助NameNode运行，将NameNode产生的元数据持久化到磁盘上 

辅助NameNode运行，将NameNode产生的元数据持久化到磁盘上

－数据库：传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。

－数据仓库：数据仓库系统的主要应用主要是OLAP（On-Line Analytical Processing），支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。

### Hadoop安装配置
- 需要安装java,不再讲述

- 官网下载hadoop发行版
    http://hadoop.apache.org/releases.html
- 下载后进行解压，移动  

        tar -zxvf hadoop-3.1.0.tar.gz 
        mv hadoop-3.1.0 /home/hadoop/hadoop/hadoop3
- 修改  ~/.bashrc 文件  
        
        # 我的java是放在桌面的，配置java环境路径
        export JAVA_HOME=/home/hadoop/Desktop/java/jdk1.8.0_171
        export PATH=$JAVA_HOME/bin:$PATH 

- 修改　vi　etc/hadoop/hadoop-env.sh  添加以下代码　　

        export JAVA_HOME=/home/hadoop/Desktop/java/jdk1.8.0_171
        export HADOOP_HOME=/home/hadoop/hadoop/hadoop3 
        export PATH=$PATH:/home/hadoop/hadoop/hadoop3/bin
- 修改　vi etc/hadoop/core-site.xml添加以下代码
       
         <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
        <description>The name of the default file system. </description>   
        </property>
        <property> 
                <name>hadoop.tmp.dir</name> 
            <value>/home/hadoop/hadoop/tmp</value>
            <description>Parent directory for other temporary directories.</description>
        </property>
        
        创建需要的文件夹
        mkdir　/home/hadoop/hadoop/tmp
        
- 修改　vi etc/hadoop/mapred-site.xml 添加以下代码

         <property> 
             <name>mapreduce.jobtracker.address</name>
                 <value>localhost:9001</value>
            <description>MapReduce job tracker runs at this host and port. </description>
         </property> 　
         
- 修改　vi etc/hadoop/yarn-site.xml 添加以下代码

        <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>ha01</value>
    	</property>
    	<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    	</property>

- 格式化HDFS

        bin/hdfs namenode -format
- 启动 Hadoop 的单节点集群  

        sbin/start-dfs.sh 
        
        sbin/start-yarn.sh
        
        查看启动jps
  
- 启动成功如下图  
![](/images/assets/hadoop.png)

- 关闭hadoop
    
        sbin/stop-dfs.sh
        sbin/stop-yarn.sh
        
- 通过WebUI查看Hadoop状态
    
            http://127.0.0.1:9870
            http://127.0.0.1:8088
        
- 使用命令行界面访问HDFS
    
    - 从本地文件系统复制文件到 HDFS

            hduser_@ubuntu:~$ $HADOOP_HOME/bin/hdfs dfs -copyFromLocal temp.txt /
    此命令将文件从本地文件系统拷贝 temp.txt 文件到 HDFS。
    
    - 我们可以通过以下命令列出一个目录下存在的文件 -ls  
    
            hduser_@ubuntu:~$ $HADOOP_HOME/bin/hdfs dfs -ls /  
        
    - 以下命令将文件从 HDFS 拷贝到本地文件系统  

            hduser_@ubuntu:~$ $HADOOP_HOME/bin/hdfs dfs -copyToLocal /temp.txt
     我们可以看到 temp.txt 已经复制到本地文件系统。    
                
    - 创建目录
        
            bin/hdfs dfs -mkdir /mydirectory

   