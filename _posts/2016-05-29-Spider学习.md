---
layout: post
title: Spider 基础
categories: Spider
description: Spider 基础
keywords: Spider
comments: true
---

>摘要 ： Spider基础学习，了解爬虫的基本流程，分类，以及spider是如何获取内容，方法的介绍，以及requests模块介绍使用



### 爬虫的定义

* 模拟客户端发送网络请求，接收请求响应

### 爬虫分类

* 通用爬虫 搜索引擎爬虫
* 聚焦爬虫 针对特定网站的爬虫

### 聚焦爬虫的流程

1. url list
2. 发送请求，获取相应 ----&gt;2.1从响应中获取url地址请求
3. 提取数据
4. 保存

### 浏览器请求获取的内容

* elements = 当前url地址对应的响应 + js + css + 图片
* 爬虫请求到的内容和elements的内容不一样，爬虫请求的是当前url对应的响应
* 提取数据时 需要要以当前url地址对应的响应为准

### 获取当前url地址对应响应的方法

* chrome中右键显示网页源码
* 打开检查，点击network，刷新页面，找到第一个地址或者是当前url地址，点击response

### http和https

#### 概念

* http 超文本传输协议
* https = http+ssl
* https比http更安全，但效率更低

#### 浏览器请求url地址的过程

* 爬虫请求到的内容和渲染的内容不一样，提取数据要以当前url地址对应的相应标准

#### 请求头

* User-Agent：用户代理，客户端识别
* cookies:关注cookie的name和value对应的值
* refrere: 表示当前的url地址是从那个url地址过来的

#### get和post体中

* 1.get请求携带的数据在url地址中，post请求在请求
* 2.psot请求携带的数据比get请求大

### python3中字符串相关的知识

* byets和str的转化 bytes转str bytes.decode\(\)
* str转bytes str.encode\(\)

#### 字符集

* ascii，gbk，unicode都是字符集
* ascii使⽤⼀个字节表示⼀个字符，unicode使⽤2
个，utf-8边⻓的编码⽅式
* utf-8是unicode的⼦集
* utf-8是变长的编码方式 1，2，3
* unicode 是2个字节
* ascii 使用1字节

### requests模块

* 发送请求 requests.get\(url,headers={}\) header是⼀个字典

#### 获取html字符串

* 1.resposne.text
str
修改解码⽅式：resposne.encoding="utf-8"
* 2.response.content
bytes
response.content.decode\(）

其他属性

response.headers
response.request.headers
response.url
response.request.url
response.status\_code
